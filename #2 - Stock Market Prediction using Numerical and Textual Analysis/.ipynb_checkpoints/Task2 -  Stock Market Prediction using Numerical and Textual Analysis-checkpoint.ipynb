{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://internship.thesparksfoundation.info/assests/img/logo.png\" width=\"300\" alt=\"thesparksfoundation logo\"  />\n",
    "</center>\n",
    "\n",
    "# The Sparks Foundation\n",
    "\n",
    "## Task 2: Stock Market Prediction using Numerical and Textual Analysis\n",
    "\n",
    "### By : Ashutosh Vyas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Problem Statement:</b> Create a hybrid model for stock price/performance prediction using numerical analysis of historical stock prices, and sentimental analysis of news headlines.\n",
    "\n",
    "\n",
    "<b>Stock to analyze and predict:</b> SENSEX (S&P BSE SENSEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "Lets import the following libraries that are required for the task:\n",
    "\n",
    "<ul>\n",
    "    <li> <b>warnings</b> </li>\n",
    "    <li> <b>math</b> </li>\n",
    "    <li> <b>pandas</b> </li>\n",
    "    <li> <b>numpy (as np)</b> </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"about_dataset\">\n",
    "    <h2>About the dataset</h2>\n",
    "    The news dataset <b>Times of India News Headlines</b> is a persistent historical archive of noteable events in the Indian subcontinent from start-2001 to end-2020, recorded in realtime by the journalists of India. It contains approximately 3.4 million events published by Times of India.\n",
    "    <br>\n",
    "    <br>\n",
    "    Times Group as a news agency, reaches out a very wide audience across Asia and drawfs every other agency in the quantity of english articles published per day. The data can be accessed at <a href=\"https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DPQMQH\">Times of India News Headlines</a>.\n",
    "    <br>\n",
    "    <br>\n",
    "    Due to the heavy daily volume over multiple years, this data offers a deep insight into Indian society, its priorities, events, issues and talking points and how they have unfolded over time. It is possible to chop this dataset into a smaller piece for a more focused analysis, based on one or more facets.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_category</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Status quo will not be disturbed at Ayodhya; s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Fissures in Hurriyat over Pak visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>America's unwanted heading for India?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>For bigwigs; it is destination Goa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Extra buses to clear tourist traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424062</th>\n",
       "      <td>20201231</td>\n",
       "      <td>city.jodhpur</td>\n",
       "      <td>Covid-19: Despite dip in cases; Rajasthan amon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424063</th>\n",
       "      <td>20201231</td>\n",
       "      <td>city.udaipur</td>\n",
       "      <td>Covid-19: Despite dip in cases; Rajasthan amon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424064</th>\n",
       "      <td>20201231</td>\n",
       "      <td>city.ajmer</td>\n",
       "      <td>Covid-19: Despite dip in cases; Rajasthan amon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424065</th>\n",
       "      <td>20201231</td>\n",
       "      <td>removed</td>\n",
       "      <td>Govt extends deadline for use of FASTag till F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424066</th>\n",
       "      <td>20201231</td>\n",
       "      <td>entertainment.bengali.movies.news</td>\n",
       "      <td>Celebs plan to party safely and responsibly on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3424067 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         publish_date                  headline_category  \\\n",
       "0            20010102                            unknown   \n",
       "1            20010102                            unknown   \n",
       "2            20010102                            unknown   \n",
       "3            20010102                            unknown   \n",
       "4            20010102                            unknown   \n",
       "...               ...                                ...   \n",
       "3424062      20201231                       city.jodhpur   \n",
       "3424063      20201231                       city.udaipur   \n",
       "3424064      20201231                         city.ajmer   \n",
       "3424065      20201231                            removed   \n",
       "3424066      20201231  entertainment.bengali.movies.news   \n",
       "\n",
       "                                             headline_text  \n",
       "0        Status quo will not be disturbed at Ayodhya; s...  \n",
       "1                      Fissures in Hurriyat over Pak visit  \n",
       "2                    America's unwanted heading for India?  \n",
       "3                       For bigwigs; it is destination Goa  \n",
       "4                     Extra buses to clear tourist traffic  \n",
       "...                                                    ...  \n",
       "3424062  Covid-19: Despite dip in cases; Rajasthan amon...  \n",
       "3424063  Covid-19: Despite dip in cases; Rajasthan amon...  \n",
       "3424064  Covid-19: Despite dip in cases; Rajasthan amon...  \n",
       "3424065  Govt extends deadline for use of FASTag till F...  \n",
       "3424066  Celebs plan to party safely and responsibly on...  \n",
       "\n",
       "[3424067 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_headlines = pd.read_csv(\"india-news-headlines.csv\")\n",
    "news_headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"about_dataset\">\n",
    "    Since our Textual Analysis dataset containing news from Times of India News Headlines is only till 31st December 2020. \n",
    "    So we will assume today is 30th December 2020 and tomorrow is 31st December 2020. \n",
    "    <br>\n",
    "    And we have to predict the stock price ((high+low+close)/3) and closing price of BSE index for tomorrow 31st December 2020.\n",
    "    <br>\n",
    "    <br>\n",
    "    We will be using <b>yfinance</b> to extract the stock data of <b>BSE SENSEX</b> from <b>02/01/2001</b> to <b>31/12/2020</b>. The <b>BSE SENSEX</b> is a free-float market-weighted stock market index of 30 well-established and financially sound companies listed on the Bombay Stock Exchange.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "bse_data = yf.download('^BSESN', start='2001-01-02', end='2020-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>3953.219971</td>\n",
       "      <td>4028.570068</td>\n",
       "      <td>3929.370117</td>\n",
       "      <td>4018.879883</td>\n",
       "      <td>4018.879883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>3977.580078</td>\n",
       "      <td>4067.659912</td>\n",
       "      <td>3977.580078</td>\n",
       "      <td>4060.020020</td>\n",
       "      <td>4060.020020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-04</th>\n",
       "      <td>4180.970215</td>\n",
       "      <td>4180.970215</td>\n",
       "      <td>4109.549805</td>\n",
       "      <td>4115.370117</td>\n",
       "      <td>4115.370117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-05</th>\n",
       "      <td>4116.339844</td>\n",
       "      <td>4195.009766</td>\n",
       "      <td>4115.350098</td>\n",
       "      <td>4183.729980</td>\n",
       "      <td>4183.729980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-08</th>\n",
       "      <td>4164.759766</td>\n",
       "      <td>4206.720215</td>\n",
       "      <td>4101.529785</td>\n",
       "      <td>4120.430176</td>\n",
       "      <td>4120.430176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2001-01-02  3953.219971  4028.570068  3929.370117  4018.879883  4018.879883   \n",
       "2001-01-03  3977.580078  4067.659912  3977.580078  4060.020020  4060.020020   \n",
       "2001-01-04  4180.970215  4180.970215  4109.549805  4115.370117  4115.370117   \n",
       "2001-01-05  4116.339844  4195.009766  4115.350098  4183.729980  4183.729980   \n",
       "2001-01-08  4164.759766  4206.720215  4101.529785  4120.430176  4120.430176   \n",
       "\n",
       "            Volume  \n",
       "Date                \n",
       "2001-01-02       0  \n",
       "2001-01-03       0  \n",
       "2001-01-04       0  \n",
       "2001-01-05       0  \n",
       "2001-01-08       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bse_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using <b>reset_index</b> to reset the index of the DataFrame, and use the default one instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-02</td>\n",
       "      <td>3953.219971</td>\n",
       "      <td>4028.570068</td>\n",
       "      <td>3929.370117</td>\n",
       "      <td>4018.879883</td>\n",
       "      <td>4018.879883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-03</td>\n",
       "      <td>3977.580078</td>\n",
       "      <td>4067.659912</td>\n",
       "      <td>3977.580078</td>\n",
       "      <td>4060.020020</td>\n",
       "      <td>4060.020020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-04</td>\n",
       "      <td>4180.970215</td>\n",
       "      <td>4180.970215</td>\n",
       "      <td>4109.549805</td>\n",
       "      <td>4115.370117</td>\n",
       "      <td>4115.370117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-05</td>\n",
       "      <td>4116.339844</td>\n",
       "      <td>4195.009766</td>\n",
       "      <td>4115.350098</td>\n",
       "      <td>4183.729980</td>\n",
       "      <td>4183.729980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-01-08</td>\n",
       "      <td>4164.759766</td>\n",
       "      <td>4206.720215</td>\n",
       "      <td>4101.529785</td>\n",
       "      <td>4120.430176</td>\n",
       "      <td>4120.430176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date         Open         High          Low        Close    Adj Close  \\\n",
       "0 2001-01-02  3953.219971  4028.570068  3929.370117  4018.879883  4018.879883   \n",
       "1 2001-01-03  3977.580078  4067.659912  3977.580078  4060.020020  4060.020020   \n",
       "2 2001-01-04  4180.970215  4180.970215  4109.549805  4115.370117  4115.370117   \n",
       "3 2001-01-05  4116.339844  4195.009766  4115.350098  4183.729980  4183.729980   \n",
       "4 2001-01-08  4164.759766  4206.720215  4101.529785  4120.430176  4120.430176   \n",
       "\n",
       "   Volume  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bse_data.reset_index(inplace=True)\n",
    "bse_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using <b>dataframe.info()</b> to get a concise summary of both dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4921 entries, 0 to 4920\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Date       4921 non-null   datetime64[ns]\n",
      " 1   Open       4921 non-null   float64       \n",
      " 2   High       4921 non-null   float64       \n",
      " 3   Low        4921 non-null   float64       \n",
      " 4   Close      4921 non-null   float64       \n",
      " 5   Adj Close  4921 non-null   float64       \n",
      " 6   Volume     4921 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(5), int64(1)\n",
      "memory usage: 269.2 KB\n"
     ]
    }
   ],
   "source": [
    "bse_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3424067 entries, 0 to 3424066\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Dtype \n",
      "---  ------             ----- \n",
      " 0   publish_date       int64 \n",
      " 1   headline_category  object\n",
      " 2   headline_text      object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 78.4+ MB\n"
     ]
    }
   ],
   "source": [
    "news_headlines.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using <b>dataframe.isna().any()</b> to checking both dataframes for any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         False\n",
       "Open         False\n",
       "High         False\n",
       "Low          False\n",
       "Close        False\n",
       "Adj Close    False\n",
       "Volume       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bse_data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "publish_date         False\n",
       "headline_category    False\n",
       "headline_text        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_headlines.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BSESN Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Dropping duplicates in <b>bse_data</b></li>\n",
    "    <li>Coverting the datatype of column <b>Date</b> from type <b>object</b> to type <b>datetime</b></li>\n",
    "    <li>Filtering the important columns i.e. <b>Date, Close, Open, High, Low</b> and <b>Volume</b></li>\n",
    "    <li>Setting column <b>Date</b> as the index column</li>\n",
    "    <li>Sorting <b>bse_data</b> according to <b>Date</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>4018.879883</td>\n",
       "      <td>3953.219971</td>\n",
       "      <td>4028.570068</td>\n",
       "      <td>3929.370117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>4060.020020</td>\n",
       "      <td>3977.580078</td>\n",
       "      <td>4067.659912</td>\n",
       "      <td>3977.580078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-04</th>\n",
       "      <td>4115.370117</td>\n",
       "      <td>4180.970215</td>\n",
       "      <td>4180.970215</td>\n",
       "      <td>4109.549805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-05</th>\n",
       "      <td>4183.729980</td>\n",
       "      <td>4116.339844</td>\n",
       "      <td>4195.009766</td>\n",
       "      <td>4115.350098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-08</th>\n",
       "      <td>4120.430176</td>\n",
       "      <td>4164.759766</td>\n",
       "      <td>4206.720215</td>\n",
       "      <td>4101.529785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-23</th>\n",
       "      <td>46444.179688</td>\n",
       "      <td>46072.300781</td>\n",
       "      <td>46513.320312</td>\n",
       "      <td>45899.101562</td>\n",
       "      <td>10500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-24</th>\n",
       "      <td>46973.539062</td>\n",
       "      <td>46743.488281</td>\n",
       "      <td>47053.398438</td>\n",
       "      <td>46539.019531</td>\n",
       "      <td>13700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>47353.750000</td>\n",
       "      <td>47153.589844</td>\n",
       "      <td>47406.718750</td>\n",
       "      <td>47148.238281</td>\n",
       "      <td>9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>47613.078125</td>\n",
       "      <td>47466.621094</td>\n",
       "      <td>47714.550781</td>\n",
       "      <td>47361.898438</td>\n",
       "      <td>12800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>47746.218750</td>\n",
       "      <td>47789.031250</td>\n",
       "      <td>47807.851562</td>\n",
       "      <td>47358.359375</td>\n",
       "      <td>15600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4921 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Close          Open          High           Low  Volume\n",
       "Date                                                                      \n",
       "2001-01-02   4018.879883   3953.219971   4028.570068   3929.370117       0\n",
       "2001-01-03   4060.020020   3977.580078   4067.659912   3977.580078       0\n",
       "2001-01-04   4115.370117   4180.970215   4180.970215   4109.549805       0\n",
       "2001-01-05   4183.729980   4116.339844   4195.009766   4115.350098       0\n",
       "2001-01-08   4120.430176   4164.759766   4206.720215   4101.529785       0\n",
       "...                  ...           ...           ...           ...     ...\n",
       "2020-12-23  46444.179688  46072.300781  46513.320312  45899.101562   10500\n",
       "2020-12-24  46973.539062  46743.488281  47053.398438  46539.019531   13700\n",
       "2020-12-28  47353.750000  47153.589844  47406.718750  47148.238281    9600\n",
       "2020-12-29  47613.078125  47466.621094  47714.550781  47361.898438   12800\n",
       "2020-12-30  47746.218750  47789.031250  47807.851562  47358.359375   15600\n",
       "\n",
       "[4921 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bse_data = bse_data.drop_duplicates()\n",
    "\n",
    "bse_data['Date'] = pd.to_datetime(bse_data['Date']).dt.normalize()\n",
    "\n",
    "bse_data = bse_data.filter(['Date', 'Close', 'Open', 'High', 'Low', 'Volume'])\n",
    "\n",
    "bse_data.set_index('Date', inplace= True)\n",
    "\n",
    "bse_data = bse_data.sort_index(ascending=True, axis=0)\n",
    "bse_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News Headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Dropping duplicates in <b>news_headlines</b></li>\n",
    "    <li>Coverting the datatype of column <b>Date</b> from type <b>object</b> to type <b>datetime</b></li>\n",
    "    <li>Filtering the important columns i.e. <b>publish_date</b> and <b>headline_text</b></li>\n",
    "    <li>Grouping the news headlines according to <b>Date</b></li>\n",
    "    <li>Setting column <b>Date</b> as the index column</li>\n",
    "    <li>Sorting <b>news_headlines</b> according to <b>Date</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publish_date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>Status quo will not be disturbed at Ayodhya; s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>Powerless north India gropes in the dark,Think...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-04</th>\n",
       "      <td>The string that pulled Stephen Hawking to Indi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-05</th>\n",
       "      <td>Light combat craft takes India into club class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-06</th>\n",
       "      <td>Light combat craft takes India into club class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-27</th>\n",
       "      <td>#BigInterview! Dhritiman Chatterjee: Nobody da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>Horoscope Today; 28 December 2020: Check astro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>Man recovers charred remains of 'thief' from h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>Numerology Readings 30 December 2020: Predicti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>Horoscope Today; 31 December 2020: Check astro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7262 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  headline_text\n",
       "publish_date                                                   \n",
       "2001-01-02    Status quo will not be disturbed at Ayodhya; s...\n",
       "2001-01-03    Powerless north India gropes in the dark,Think...\n",
       "2001-01-04    The string that pulled Stephen Hawking to Indi...\n",
       "2001-01-05    Light combat craft takes India into club class...\n",
       "2001-01-06    Light combat craft takes India into club class...\n",
       "...                                                         ...\n",
       "2020-12-27    #BigInterview! Dhritiman Chatterjee: Nobody da...\n",
       "2020-12-28    Horoscope Today; 28 December 2020: Check astro...\n",
       "2020-12-29    Man recovers charred remains of 'thief' from h...\n",
       "2020-12-30    Numerology Readings 30 December 2020: Predicti...\n",
       "2020-12-31    Horoscope Today; 31 December 2020: Check astro...\n",
       "\n",
       "[7262 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_headlines = news_headlines.drop_duplicates()\n",
    "\n",
    "news_headlines['publish_date'] = news_headlines['publish_date'].astype(str)\n",
    "news_headlines['publish_date'] = news_headlines['publish_date'].apply(lambda x: x[0:4]+'-'+x[4:6]+'-'+x[6:8])\n",
    "news_headlines['publish_date'] = pd.to_datetime(news_headlines['publish_date']).dt.normalize()\n",
    "\n",
    "news_headlines = news_headlines.filter(['publish_date', 'headline_text'])\n",
    "\n",
    "news_headlines = news_headlines.groupby(['publish_date'])['headline_text'].apply(lambda x: ','.join(x)).reset_index()\n",
    "\n",
    "news_headlines.set_index('publish_date', inplace= True)\n",
    "\n",
    "news_headlines = news_headlines.sort_index(ascending=True, axis=0)\n",
    "news_headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining both Prices and Headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Concatenating the datasets: <b>bse_data</b> and <b>news_headlines</b></li>\n",
    "    <li>Displaying the combined <b>stock_data</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>4018.879883</td>\n",
       "      <td>3953.219971</td>\n",
       "      <td>4028.570068</td>\n",
       "      <td>3929.370117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Status quo will not be disturbed at Ayodhya; s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>4060.020020</td>\n",
       "      <td>3977.580078</td>\n",
       "      <td>4067.659912</td>\n",
       "      <td>3977.580078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Powerless north India gropes in the dark,Think...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-04</th>\n",
       "      <td>4115.370117</td>\n",
       "      <td>4180.970215</td>\n",
       "      <td>4180.970215</td>\n",
       "      <td>4109.549805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The string that pulled Stephen Hawking to Indi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-05</th>\n",
       "      <td>4183.729980</td>\n",
       "      <td>4116.339844</td>\n",
       "      <td>4195.009766</td>\n",
       "      <td>4115.350098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Light combat craft takes India into club class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-08</th>\n",
       "      <td>4120.430176</td>\n",
       "      <td>4164.759766</td>\n",
       "      <td>4206.720215</td>\n",
       "      <td>4101.529785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sangh Parivar; Babri panel up the ante,Frontru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-23</th>\n",
       "      <td>46444.179688</td>\n",
       "      <td>46072.300781</td>\n",
       "      <td>46513.320312</td>\n",
       "      <td>45899.101562</td>\n",
       "      <td>10500.0</td>\n",
       "      <td>Sawmill in Makarpura GIDC gutted; none hurt,Ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-24</th>\n",
       "      <td>46973.539062</td>\n",
       "      <td>46743.488281</td>\n",
       "      <td>47053.398438</td>\n",
       "      <td>46539.019531</td>\n",
       "      <td>13700.0</td>\n",
       "      <td>How to set the mood for sex during cold winter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>47353.750000</td>\n",
       "      <td>47153.589844</td>\n",
       "      <td>47406.718750</td>\n",
       "      <td>47148.238281</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>Horoscope Today; 28 December 2020: Check astro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>47613.078125</td>\n",
       "      <td>47466.621094</td>\n",
       "      <td>47714.550781</td>\n",
       "      <td>47361.898438</td>\n",
       "      <td>12800.0</td>\n",
       "      <td>Man recovers charred remains of 'thief' from h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>47746.218750</td>\n",
       "      <td>47789.031250</td>\n",
       "      <td>47807.851562</td>\n",
       "      <td>47358.359375</td>\n",
       "      <td>15600.0</td>\n",
       "      <td>Numerology Readings 30 December 2020: Predicti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4892 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Close          Open          High           Low   Volume  \\\n",
       "2001-01-02   4018.879883   3953.219971   4028.570068   3929.370117      0.0   \n",
       "2001-01-03   4060.020020   3977.580078   4067.659912   3977.580078      0.0   \n",
       "2001-01-04   4115.370117   4180.970215   4180.970215   4109.549805      0.0   \n",
       "2001-01-05   4183.729980   4116.339844   4195.009766   4115.350098      0.0   \n",
       "2001-01-08   4120.430176   4164.759766   4206.720215   4101.529785      0.0   \n",
       "...                  ...           ...           ...           ...      ...   \n",
       "2020-12-23  46444.179688  46072.300781  46513.320312  45899.101562  10500.0   \n",
       "2020-12-24  46973.539062  46743.488281  47053.398438  46539.019531  13700.0   \n",
       "2020-12-28  47353.750000  47153.589844  47406.718750  47148.238281   9600.0   \n",
       "2020-12-29  47613.078125  47466.621094  47714.550781  47361.898438  12800.0   \n",
       "2020-12-30  47746.218750  47789.031250  47807.851562  47358.359375  15600.0   \n",
       "\n",
       "                                                headline_text  \n",
       "2001-01-02  Status quo will not be disturbed at Ayodhya; s...  \n",
       "2001-01-03  Powerless north India gropes in the dark,Think...  \n",
       "2001-01-04  The string that pulled Stephen Hawking to Indi...  \n",
       "2001-01-05  Light combat craft takes India into club class...  \n",
       "2001-01-08  Sangh Parivar; Babri panel up the ante,Frontru...  \n",
       "...                                                       ...  \n",
       "2020-12-23  Sawmill in Makarpura GIDC gutted; none hurt,Ci...  \n",
       "2020-12-24  How to set the mood for sex during cold winter...  \n",
       "2020-12-28  Horoscope Today; 28 December 2020: Check astro...  \n",
       "2020-12-29  Man recovers charred remains of 'thief' from h...  \n",
       "2020-12-30  Numerology Readings 30 December 2020: Predicti...  \n",
       "\n",
       "[4892 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data = pd.concat([bse_data, news_headlines], axis=1)\n",
    "\n",
    "stock_data.dropna(axis=0, inplace=True)\n",
    "\n",
    "stock_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding new columns: <b>[compound, negative, neutral, positive]</b> to <b>stock_data</b> to perform Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>headline_text</th>\n",
       "      <th>compound</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>4018.879883</td>\n",
       "      <td>3953.219971</td>\n",
       "      <td>4028.570068</td>\n",
       "      <td>3929.370117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Status quo will not be disturbed at Ayodhya; s...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>4060.020020</td>\n",
       "      <td>3977.580078</td>\n",
       "      <td>4067.659912</td>\n",
       "      <td>3977.580078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Powerless north India gropes in the dark,Think...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-04</th>\n",
       "      <td>4115.370117</td>\n",
       "      <td>4180.970215</td>\n",
       "      <td>4180.970215</td>\n",
       "      <td>4109.549805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The string that pulled Stephen Hawking to Indi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-05</th>\n",
       "      <td>4183.729980</td>\n",
       "      <td>4116.339844</td>\n",
       "      <td>4195.009766</td>\n",
       "      <td>4115.350098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Light combat craft takes India into club class...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-08</th>\n",
       "      <td>4120.430176</td>\n",
       "      <td>4164.759766</td>\n",
       "      <td>4206.720215</td>\n",
       "      <td>4101.529785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sangh Parivar; Babri panel up the ante,Frontru...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Close         Open         High          Low  Volume  \\\n",
       "2001-01-02  4018.879883  3953.219971  4028.570068  3929.370117     0.0   \n",
       "2001-01-03  4060.020020  3977.580078  4067.659912  3977.580078     0.0   \n",
       "2001-01-04  4115.370117  4180.970215  4180.970215  4109.549805     0.0   \n",
       "2001-01-05  4183.729980  4116.339844  4195.009766  4115.350098     0.0   \n",
       "2001-01-08  4120.430176  4164.759766  4206.720215  4101.529785     0.0   \n",
       "\n",
       "                                                headline_text compound  \\\n",
       "2001-01-02  Status quo will not be disturbed at Ayodhya; s...            \n",
       "2001-01-03  Powerless north India gropes in the dark,Think...            \n",
       "2001-01-04  The string that pulled Stephen Hawking to Indi...            \n",
       "2001-01-05  Light combat craft takes India into club class...            \n",
       "2001-01-08  Sangh Parivar; Babri panel up the ante,Frontru...            \n",
       "\n",
       "           negative neutral positive  \n",
       "2001-01-02                            \n",
       "2001-01-03                            \n",
       "2001-01-04                            \n",
       "2001-01-05                            \n",
       "2001-01-08                            "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data['compound'] = ''\n",
    "stock_data['negative'] = ''\n",
    "stock_data['neutral'] = ''\n",
    "stock_data['positive'] = ''\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries to perfrom Sentiment Analysis\n",
    "Lets import the following libraries that are required for the task:\n",
    "\n",
    "<ul>\n",
    "    <li> <b>nltk</b> </li>\n",
    "    <li> <b>SentimentIntensityAnalyzer</b> from <b>nltk.sentiment.vader</b> </li>\n",
    "</ul>\n",
    "\n",
    "Also let's download <b>vader_lexicon</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "# from nltk.classify import NaiveBayesClassifier\n",
    "# from nltk.corpus import subjectivity\n",
    "# from nltk.sentiment import SentimentAnalyzer\n",
    "# from nltk.sentiment.util import *\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import unicodedata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating sentiment scores:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a1010fd0b4d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Start calculating sentiment scores:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mstock_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'compound'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstock_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'headline_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'compound'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Compound Done'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mstock_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'negative'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstock_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'headline_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'neg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4200\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-a1010fd0b4d0>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Start calculating sentiment scores:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mstock_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'compound'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstock_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'headline_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'compound'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Compound Done'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mstock_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'negative'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstock_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'headline_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'neg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\nltk\\sentiment\\vader.py\u001b[0m in \u001b[0;36mpolarity_scores\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwords_and_emoticons\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             if (\n\u001b[1;32m--> 368\u001b[1;33m                 \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords_and_emoticons\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m                 \u001b[1;32mand\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"kind\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m                 \u001b[1;32mand\u001b[0m \u001b[0mwords_and_emoticons\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"of\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "print('Start calculating sentiment scores:')\n",
    "\n",
    "stock_data['compound'] = stock_data['headline_text'].apply(lambda x: sid.polarity_scores(x)['compound'])\n",
    "print('Compound Done')\n",
    "stock_data['negative'] = stock_data['headline_text'].apply(lambda x: sid.polarity_scores(x)['neg'])\n",
    "print('Negative Done')\n",
    "stock_data['neutral'] = stock_data['headline_text'].apply(lambda x: sid.polarity_scores(x)['neu'])\n",
    "print('Neutral Done')\n",
    "stock_data['positive'] = stock_data['headline_text'].apply(lambda x: sid.polarity_scores(x)['pos'])\n",
    "print('Positive Done')\n",
    "print('Stop')\n",
    "\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Dropping unwanted <b>headline_text</b> and rearranging columns</li>\n",
    "    <li>Displaying final <b>stock_data<b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data.drop(['headline_text'], inplace=True, axis=1)\n",
    "stock_data = stock_data[['Close', 'compound', 'negative', 'neutral', 'positive', 'Open', 'High', 'Low', 'Volume']]\n",
    "\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering of the Combined Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Using <b>dataframe.isna().any()</b> to checking <b>stock_data</b> for any null values</li>\n",
    "    <li>Using <b>dataframe.describe()</b> to view some basic statistical details like percentile, mean, std etc. of <b>stock_data</b></li>\n",
    "    <li>Using <b>dataframe.info()</b> to get a concise summary of <b>stock_data</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "stock_data['Close'].plot()\n",
    "\n",
    "\n",
    "plt.title(\"Close Price\")\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price (INR)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating 7 day rolling mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data.rolling(7).mean().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting figure size\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "# plotting the close price and a 30-day rolling mean of close price\n",
    "stock_data['Close'].plot()\n",
    "stock_data.rolling(window=30).mean()['Close'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data For Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating data_to_use\n",
    "percentage_of_data = 1.0\n",
    "data_to_use = int(percentage_of_data*(len(stock_data)-1))\n",
    "\n",
    "# using 80% of data for training\n",
    "train_end = int(data_to_use*0.8)\n",
    "total_data = len(stock_data)\n",
    "start = total_data - data_to_use\n",
    "\n",
    "# printing number of records in the training and test datasets\n",
    "print(\"Number of records in Training Data:\", train_end)\n",
    "print(\"Number of records in Test Data:\", total_data - train_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting one step ahead\n",
    "steps_to_predict = 1\n",
    "\n",
    "\n",
    "close_price = stock_data.iloc[start:total_data,0] #close\n",
    "compound = stock_data.iloc[start:total_data,1] #compound\n",
    "negative = stock_data.iloc[start:total_data,2] #neg\n",
    "neutral = stock_data.iloc[start:total_data,3] #neu\n",
    "positive = stock_data.iloc[start:total_data,4] #pos\n",
    "open_price = stock_data.iloc[start:total_data,5] #open\n",
    "high = stock_data.iloc[start:total_data,6] #high\n",
    "low = stock_data.iloc[start:total_data,7] #low\n",
    "volume = stock_data.iloc[start:total_data,8] #volume\n",
    "\n",
    "# printing close price\n",
    "print(\"Close Price:\")\n",
    "close_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shifting next day close\n",
    "close_price_shifted = close_price.shift(-1) \n",
    "\n",
    "# shifting next day compound\n",
    "compound_shifted = compound.shift(-1) \n",
    "\n",
    "# concatenating the captured training data into a dataframe\n",
    "data = pd.concat([close_price, close_price_shifted, compound, compound_shifted, volume, open_price, high, low], axis=1)\n",
    "\n",
    "# setting column names of the revised stock data\n",
    "data.columns = ['close_price', 'close_price_shifted', 'compound', 'compound_shifted','volume', 'open_price', 'high', 'low']\n",
    "\n",
    "# dropping nulls\n",
    "data = data.dropna()    \n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close price shifted set as the target var\n",
    "y = data['close_price_shifted']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the features dataset for prediction  \n",
    "cols = ['close_price', 'compound', 'compound_shifted', 'volume', 'open_price', 'high', 'low']\n",
    "x = data[cols]\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries to Scale the data\n",
    "Lets import the following library that is required for the task:\n",
    "\n",
    "<ul>\n",
    "    <li> <b>MinMaxScaler</b> from <b>sklearn.preprocessing</b> </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the feature dataset\n",
    "scaler_x = MinMaxScaler(feature_range=(-1, 1))\n",
    "x = np.array(x).reshape((len(x) ,len(cols)))\n",
    "x = scaler_x.fit_transform(x)\n",
    "\n",
    "# scaling the target variable\n",
    "scaler_y = MinMaxScaler(feature_range=(-1, 1))\n",
    "y = np.array (y).reshape ((len( y), 1))\n",
    "y = scaler_y.fit_transform (y)\n",
    "\n",
    "# displaying the scaled feature dataset and the target variable\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing data for training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing training and test dataset\n",
    "X_train = x[0 : train_end,]\n",
    "X_test = x[train_end+1 : len(x),]    \n",
    "y_train = y[0 : train_end] \n",
    "y_test = y[train_end+1 : len(y)]  \n",
    "\n",
    "# printing the shape of the training and the test datasets\n",
    "print('Number of rows and columns in Training set X:', X_train.shape, 'and y:', y_train.shape)\n",
    "print('Number of rows and columns in Test set X:', X_test.shape, 'and y:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping dataset\n",
    "X_train = X_train.reshape(X_train.shape+(1,))\n",
    "X_test = X_test.reshape(X_test.shape+(1,))\n",
    "\n",
    "\n",
    "print('Shape of Training set X:', X_train.shape)\n",
    "print('Shape of Test set X:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Sequential Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries to Create Sequential Model\n",
    "Lets import the following libraries that are required for the task:\n",
    "\n",
    "<ul>\n",
    "    <li> <b>Sequential</b> from <b>keras.models</b> </li>\n",
    "    <li> <b>Dense, LSTM, Dropout, Dense, Activation</b> from <b>keras.layers</b> </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed set to achieve consistent and less random predictions\n",
    "np.random.seed(2016)\n",
    "\n",
    "# setting the architecture for the data model\n",
    "model=Sequential()\n",
    "model.add(LSTM(100,return_sequences=True,activation='tanh',input_shape=(len(cols),1)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(100,return_sequences=True,activation='tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(100,activation='tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# printing the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse' , optimizer='adam')\n",
    "\n",
    "# fitting the model using the training dataset\n",
    "model.fit(X_train, y_train, validation_split=0.2, batch_size=8, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save_weights('model.h5')\n",
    "print('Model is saved to the disk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "predictions = scaler_y.inverse_transform(np.array(predictions).reshape((len(predictions),1)))\n",
    "\n",
    "print('Predictions:')\n",
    "predictions[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries to Evaluate The Model\n",
    "Lets import the following library that is required for the task:\n",
    "\n",
    "<ul>\n",
    "    <li> <b>metrics</b> from <b>sklearn</b> </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model using various Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>Train Loss</b> and <b>Test Loss</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the training mX_trainsquared-error\n",
    "train_loss = model.evaluate(X_train, y_train, batch_size = 1)\n",
    "# calculating the test mean-squared-error\n",
    "\n",
    "test_loss = model.evaluate(X_test, y_test, batch_size = 1)\n",
    "# printing the training and the test mean-squared-errors\n",
    "print('Train Loss =', round(train_loss, 4) )\n",
    "print ('Test Loss =', round(test_loss, 4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Root Mean Square Error </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating root mean squared error\n",
    "root_mean_square_error = np.sqrt(np.mean(np.power((y_test- predictions) , 2) ) )\n",
    "print ('Root Mean Square Error:', round(root_mean_square_error, 4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Root Mean Square Error (sklearn.metrics)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating root mean squared error using sklearn.metrics package\n",
    "rmse = metrics.mean_squared_error(y_test, predictions)\n",
    "print('Root Mean Square Error (sklearn.metrics):', round(np.sqrt(rmse) , 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Unscaling the test feature dataset: <b>x_test</b> and test y dataset: <b>y_test</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scaler_x.inverse_transform(np.array(X_test).reshape((len(X_test), len(cols))))\n",
    "\n",
    "y_train = scaler_y.inverse_transform(np.array(y_train).reshape((len(y_train) , 1)))\n",
    "\n",
    "y_test = scaler_y.inverse_transform(np.array(y_test).reshape((len(y_test), 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Predicted data against Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17, 10))\n",
    "\n",
    "plt.plot(predictions, label=\"Predicted Close price\")\n",
    "plt.plot([row[0] for row in y_test], label = \"Testing Close Price\")\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=2, prop={'size': 20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
